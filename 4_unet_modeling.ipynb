{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2tsEZB+GdPsL+/NzVO/qb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariegever/ImageProcessing_Project/blob/main/4_unet_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#=== HOW TO USE THIS NOTEBOOK ===\n",
        "#\n",
        "# 1.  **Set Runtime:** Go to \"Runtime\" > \"Change runtime type\" and select\n",
        "#     \"T4 GPU\" (or any available GPU) as the \"Hardware accelerator\".\n",
        "#     This is *critical* for training your model.\n",
        "#\n",
        "# 2.  **Configuration:**\n",
        "#     * Configuration is now handled in `config.py`.\n",
        "#\n",
        "# 3.  **Run All Remaining Cells:**\n",
        "#     * The notebook will load your class definitions, prepare the data\n",
        "#       pipeline, build your U-Net model, and start training."
      ],
      "metadata": {
        "id": "AbkkuK79Zebc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import config\n",
        "drive.mount(config.DRIVE_MOUNT_PATH)\n",
        "from google.colab import auth\n",
        "import google.auth\n",
        "import ee\n",
        "# Trigger the authentication flow.\n",
        "auth.authenticate_user()\n",
        "# Get credentials and initialize Earth Engine\n",
        "credentials, project = google.auth.default()\n",
        "ee.Initialize(credentials, project=config.PROJECT_ID, opt_url='https://earthengine-highvolume.googleapis.com')\n",
        "\n",
        "print(f\"Successfully initialized Earth Engine for project: {config.PROJECT_ID}\")\n",
        "!pip install  scikit-learn scikit-image rasterio\n",
        "!pip install keras\n",
        "\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import utils\n",
        "\n",
        "# TensorFlow / Keras\n",
        "import tensorflow as tf\n",
        "import tensorflow as keras\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Dropout, MaxPooling2D, Input, concatenate\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Scikit-learn for metrics\n",
        "# We will add cohen_kappa_score here\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, cohen_kappa_score\n",
        "\n",
        "# Matplotlib helpers\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.colors import ListedColormap\n",
        "from skimage.exposure import rescale_intensity"
      ],
      "metadata": {
        "id": "-zHmp-kRZtj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Configuration from config.py ===\n",
        "\n",
        "TFRECORD_FILE_PATH = os.path.join(config.DRIVE_IMAGES_PATH, config.TFRECORD_FILE)\n",
        "HISTORY_CSV_PATH = os.path.join(config.DRIVE_IMAGES_PATH, config.HISTORY_CSV_FILENAME)\n",
        "\n",
        "# This is where your final trained model will be saved\n",
        "MODEL_SAVE_PATH = os.path.join(config.DRIVE_IMAGES_PATH, config.MODEL_FILENAME)\n",
        "LATEST_CHECKPOINT_PATH = os.path.join(config.DRIVE_IMAGES_PATH, 'latest_checkpoint.weights.h5')\n",
        "BEST_CHECKPOINT_PATH = os.path.join(config.DRIVE_IMAGES_PATH, 'best_checkpoint.weights.h5')\n",
        "\n",
        "print(f\"--- Configuration ---\")\n",
        "print(f\"Project: {config.PROJECT_ID}\")\n",
        "print(f\"TFRecord File: {TFRECORD_FILE_PATH}\")\n",
        "print(f\"Model Save Path: {MODEL_SAVE_PATH}\")\n",
        "print(f\"Input Bands ({config.NUM_BANDS}): {config.FEATURE_NAMES}\")\n",
        "print(f\"Batch Size: {config.BATCH_SIZE}\")"
      ],
      "metadata": {
        "id": "16fqrQQiZvOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# 1. Load the JSON\n",
        "try:\n",
        "    with open(config.CLASS_JSON_PATH) as f:\n",
        "        lc = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: '{config.CLASS_JSON_PATH}' not found.\")\n",
        "    raise\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"ERROR: '{config.CLASS_JSON_PATH}' is not a valid JSON file.\")\n",
        "    raise\n",
        "\n",
        "\n",
        "# 2. Create DataFrame for the Main Classes (Parent Groups)\n",
        "lc_df = pd.DataFrame.from_dict(lc, orient='index')\n",
        "lc_df = lc_df.rename(columns={'class': 'label', 'color': 'palette'})\n",
        "\n",
        "# Define the target values (e.g., 1, 2, 3...)\n",
        "lc_df[\"target_value\"] = lc_df.index.astype(int) + 1\n",
        "\n",
        "# 3. Flatten the nested data to create 'from_values' and 'to_values'\n",
        "# We map the specific IDs (11, 21) to the PARENT ID (1, 2)\n",
        "from_values = []\n",
        "to_values = []\n",
        "\n",
        "for index, row in lc_df.iterrows():\n",
        "    target = row['target_value']\n",
        "    for item in row['original_classes']:\n",
        "        from_values.append(item['values']) # e.g. 21\n",
        "        to_values.append(target)       # e.g. 2\n",
        "\n",
        "# 4. Setup Palette and Visuals for 5 Classes\n",
        "class_labels = lc_df[\"label\"].to_list()\n",
        "palette_hex = lc_df[\"palette\"].to_list()\n",
        "cmap = ListedColormap(palette_hex)\n",
        "NUM_CLASSES = len(lc_df) + 1\n",
        "vmin = 0\n",
        "vmax = len(class_labels)\n",
        "\n",
        "print(f\"Reduced complexity: Mapping {len(from_values)} specific types to {len(lc_df)} parent classes.\")\n",
        "lc_df"
      ],
      "metadata": {
        "id": "9eC-abwAbJzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data pipeline functions are now in utils.py\n",
        "print(\"TFRecord data pipeline functions defined in utils.py.\")"
      ],
      "metadata": {
        "id": "_YJkWYaTc0tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Count the total number of samples ---\n",
        "print(f\"Counting samples in {TFRECORD_FILE_PATH}...\")\n",
        "count_ds = tf.data.TFRecordDataset(TFRECORD_FILE_PATH, compression_type=\"GZIP\")\n",
        "total_samples = 0\n",
        "for _ in count_ds:\n",
        "    total_samples += 1\n",
        "\n",
        "print(f\"Total samples found: {total_samples}\")\n",
        "\n",
        "# --- 2. Define splits ---\n",
        "train_size = int(total_samples * config.TRAIN_SPLIT)\n",
        "val_size = int(total_samples * config.VAL_SPLIT)\n",
        "test_size = total_samples - train_size - val_size\n",
        "\n",
        "print(f\"Train: {train_size}, Val: {val_size}, Test: {test_size}\")\n",
        "\n",
        "# --- 3. Create the main dataset ---\n",
        "full_dataset = utils.create_dataset(TFRECORD_FILE_PATH, NUM_CLASSES, is_training=False)\n",
        "\n",
        "# Unbatch to split, then re-batch\n",
        "full_dataset = full_dataset.unbatch()\n",
        "\n",
        "train_ds = full_dataset.take(train_size)\n",
        "remaining = full_dataset.skip(train_size)\n",
        "val_ds = remaining.take(val_size)\n",
        "test_ds = remaining.skip(val_size)\n",
        "\n",
        "# --- 4. Prepare for Training ---\n",
        "# Apply shuffling and augmentation ONLY to training data\n",
        "train_ds = train_ds.shuffle(config.BUFFER_SIZE).map(utils.augment_data, num_parallel_calls=tf.data.AUTOTUNE).batch(config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.batch(config.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"Datasets prepared.\")"
      ],
      "metadata": {
        "id": "dataset_preparation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet_model(input_shape, num_classes):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    # Expansive path\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "input_shape = (config.PATCH_SIZE, config.PATCH_SIZE, config.NUM_BANDS)\n",
        "model = build_unet_model(input_shape, NUM_CLASSES)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "model_building"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Train the model ---\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1, restore_best_weights=True),\n",
        "    ModelCheckpoint(BEST_CHECKPOINT_PATH, save_best_only=True, save_weights_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=config.EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Save the final model\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
        "\n",
        "# Save history\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.to_csv(HISTORY_CSV_PATH)\n",
        "print(f\"History saved to {HISTORY_CSV_PATH}\")"
      ],
      "metadata": {
        "id": "model_training"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}